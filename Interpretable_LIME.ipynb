{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPcNGHE5LdZb00oVYGFACaO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Antara999333/Assignment-5---Explainable-Techniques/blob/main/Interpretable_LIME.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Please use this to connect your GitHub repository to your Google Colab notebook\n",
        "# Connects to any needed files from GitHub and Google Drive\n",
        "import os\n",
        "\n",
        "# Remove Colab default sample_data\n",
        "!rm -r ./sample_data\n",
        "\n",
        "# Clone GitHub files to colab workspace\n",
        "repo_name = \"Duke-AI-XAI\" # Change to your repo name\n",
        "git_path = 'https://github.com/AIPI-590-XAI/Duke-AI-XAI.git' #Change to your path\n",
        "!git clone \"{git_path}\"\n",
        "\n",
        "# Install dependencies from requirements.txt file\n",
        "#!pip install -r \"{os.path.join(repo_name,'requirements.txt')}\" #Add if using requirements.txt\n",
        "\n",
        "# Change working directory to location of notebook\n",
        "notebook_dir = 'templates'\n",
        "path_to_notebook = os.path.join(repo_name,notebook_dir)\n",
        "%cd \"{path_to_notebook}\"\n",
        "%ls"
      ],
      "metadata": {
        "id": "i0UVA0BuUXkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6CqoynDAUUxh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ow0mA8fJGxlK"
      },
      "outputs": [],
      "source": [
        "pip install transformers datasets lime\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n",
        "from datasets import load_dataset\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "\n",
        "# Step 1: Load the pre-trained BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment', num_labels=5)  # Changed model for sentiment analysis\n",
        "\n",
        "# Step 2: Set up the sentiment analysis pipeline using the pre-trained BERT model\n",
        "classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer, device=0)  # Removed disable_tqdm\n",
        "\n",
        "# Step 3: Load the IMDb dataset directly from Hugging Face datasets\n",
        "imdb_dataset = load_dataset('imdb', split='train[:100]')  # Only load the first 100 entries for testing\n",
        "print(imdb_dataset[0])  # Show a sample entry from the dataset\n",
        "\n",
        "# Step 4: Randomly pick a sample text for analysis and prediction\n",
        "# Replace this with a specific index if you want to select a specific comment\n",
        "random_index = random.randint(0, len(imdb_dataset) - 1)\n",
        "sample_text = imdb_dataset[random_index]['text']\n",
        "print(f\"Sample review: {sample_text}\")\n",
        "\n",
        "# Step 5: Run sentiment analysis on the sample text\n",
        "result = classifier(sample_text)\n",
        "print(f\"Sentiment prediction: {result}\")\n",
        "\n",
        "# Step 6: Define a function to use for LIME to predict probabilities\n",
        "def predict_proba(texts):\n",
        "    batch_size = 8  # Adjust the batch size as needed\n",
        "    probabilities = []\n",
        "\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i + batch_size]\n",
        "        results = classifier(batch_texts)\n",
        "\n",
        "        for res in results:\n",
        "            if res['label'] == 'LABEL_0':\n",
        "                probabilities.append([1 - res['score'], res['score']])\n",
        "            else:\n",
        "                probabilities.append([res['score'], 1 - res['score']])\n",
        "\n",
        "    return np.array(probabilities)\n",
        "\n",
        "# Step 7: Initialize LIME explainer\n",
        "explainer = LimeTextExplainer(class_names=[\"negative\", \"positive\"])\n",
        "\n",
        "# Step 8: Generate a local explanation for the sentiment prediction on the sample text\n",
        "exp = explainer.explain_instance(sample_text, predict_proba, num_features=6)\n",
        "\n",
        "# Step 9: Display the explanation in the notebook\n",
        "exp.show_in_notebook(text=True)\n",
        "\n",
        "# Optional: Save the explanation as an HTML file\n",
        "exp.save_to_file('lime_explanation.html')\n",
        "\n"
      ],
      "metadata": {
        "id": "NY9FgqzKSL2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RESULT\n",
        "\n",
        "We can see that the model predicted the sentiment to be a bit more negative than positive. LIME also highlighted the words the words that were involved in making this decision and as provided their weights."
      ],
      "metadata": {
        "id": "HyVb6l5epjC5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WHY I CHOSE LIME\n",
        "I chose LIME (Local Interpretable Model-agnostic Explanations) as the explanation technique for my sentiment analysis dataset from IMDb because of its model-agnostic nature, which allows it to generate explanations for the BERT model used for sentiment classification. This flexibility is very important when dealing with various input text since it highlights how specific words in movie reviews contribute to predictions of positive or negative sentiment.\n",
        "\n",
        "# LIMITATIONS\n",
        "LIME can be sensitive to perturbations in a way that small modifications in the text may lead to inconsistent explanations. LIME also relies on sampling to create perturbed versions of the input, which can introduce variability and increase computational costs.\n",
        "\n",
        "# IMPROVEMENTS\n",
        "To improve my approach, I could explore using SHAP (SHapley Additive exPlanations) for comparison because it provides consistent feature importance scores that could lessen some variability that we might see with LIME."
      ],
      "metadata": {
        "id": "9g5E8yT4ndPC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L9_3J5Ci1ZWs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}